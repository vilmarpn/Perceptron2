{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The perceptron\n",
    "\n",
    "Perceptrons, invented in the [1957]( https://en.wikipedia.org/wiki/Perceptron#History) by Frank Rosenblatt, are the simpliest form of feedforward networks. They are [linear classifiers](https://en.wikipedia.org/wiki/Linear_classifier) because they find a linear function to predict if a piece of data belongs to a determined class or not. A perceptron is basically formed by a layer of input units and a layer of output units. In the simpliest case the output layer is formed by just one unit:\n",
    "\n",
    "![](perceptron.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>Table of contents</div>\n",
    "<div id=\"toc\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definitions\n",
    "The first layer of units is $\\mathbf{x} = (x_0,\\dots,x_{n+1})$. At each timestep all units of this layer are filled up with values from an input vector $\\mathbf{p}_k = (1, p_0,\\dots,p_n)$. The first element of the input is permanently set to 1. We call the first unit receiving the steady signal the bias unit. Each connection from a unit $x_i$ of the first layer to the output unit $y$ has a weight $w_i$ that is initially set to 0.\n",
    "\n",
    "### Spreading  of activations\n",
    "The activation of the output unit is given by:\n",
    "\n",
    "$$ \n",
    "\\begin{eqnarray}\n",
    "&net = \\sum_{i} w_i x_i\\\\\n",
    "&y = \\begin{cases}\n",
    "  1  & \\quad \\text{if } net >  0\\\\\n",
    "  0  & \\quad \\text{otherwise}\\\\\n",
    "  \\end{cases}\\\\\n",
    "\\end{eqnarray}\n",
    "$$ \n",
    "where $net$ is the weighted sum of the inputs.\n",
    "\n",
    "Using linear algebra we can rewrite $net$ in a shorter form as:\n",
    "$$ \n",
    "net = \\mathbf{w}^T\\mathbf{x}\n",
    "$$ \n",
    "\n",
    "\n",
    "where $\\mathbf{w}^T$ is the vector  $\\mathbf{w} = (w_0, \\dots, w_{n+1})$ translated into a row vector and $\\mathbf{w}^T\\mathbf{x}$ is the [dot product](https://en.wikipedia.org/wiki/Dot_product#Algebraic_definition), a linear algebra operator that allows to calculate the  weighted sum at once.\n",
    ">Given two vectors of the same size $\\mathbf{a} \\in \\mathbb{R}^n$ and $\\mathbf{b} \\in \\mathbb{R}^n$, the dot product $\\mathbf{a}^T\\mathbf{b}$ produces  the *scalar value* $a_0 b_0 + \\dots +a_n b_n$.\n",
    "\n",
    "In python you write:\n",
    "```python\n",
    "#The first unit is a bias unit\n",
    "x[0] = 1\n",
    "\n",
    "# Fill the rest of the x layer \n",
    "# with p values\n",
    "for i in xrange(1,n) :\n",
    "    x[i] = p[i]\n",
    "\n",
    "# Clear y\n",
    "net = 0\n",
    "\n",
    "# Fill up with the weighted \n",
    "# sum of inputs \n",
    "for i in xrange(n) :\n",
    "    net += w[i]*x[i]\n",
    "    \n",
    "# Evaluate the output\n",
    "y = 1*(net > 0)\n",
    "```\n",
    "\n",
    "Using pylab, which has linear algebra functionalities, it becomes:\n",
    "```python\n",
    "# Fill the x layer with p values\n",
    "# with the exception of the first unit\n",
    "x = hstack([1, p])\n",
    "\n",
    "# Evalutate the weighted sum - dot product\n",
    "net = dot(w,x)\n",
    "\n",
    "# Evaluate the output\n",
    "y = step(net)\n",
    "```\n",
    "Where ```step(x)``` is the step function, defined as:\n",
    "```\n",
    "def step(x) :\n",
    "    return 1*(x>0)\n",
    "```\n",
    "\n",
    "*Using linear algebra in a neural network implementation is far simpler than writing loops, it is less error prone and also produces a much efficient code in terms of speed!!*\n",
    "\n",
    "If the network is composed of more than one output units, the weighted sums can be expressed as:\n",
    "$$\n",
    "net_j = \\sum_{i}\\sum_{j} w_{ij} x_i\n",
    "$$\n",
    "and they can be written in linear algebra notation as:\n",
    "$$\n",
    "\\mathbf{net} = \\mathbf{W}\\mathbf{x}\n",
    "$$\n",
    "where $ \\mathbf{net} = (y_0, \\dots, y_m)$ is the vector of weighted sums, $\\mathbf{W} \\in \\mathbb{R}^{m\\times n}$  is the matrix of weights from $ \\mathbf{x}$ to $ \\mathbf{y}$, and $\\mathbf{W}\\mathbf{x}$ is a multiplication of a matrix  times a vector, that is the [matrix product](https://en.wikipedia.org/wiki/Matrix_multiplication#Matrix_product_.28two_matrices.29) of which the dot product is a [special case](https://en.wikipedia.org/wiki/Matrix_multiplication#Row_vector_and_column_vector).\n",
    "\n",
    ">Given two matrices $\\mathbf{A} \\in \\mathbb{R}^{m\\times k}$ and $\\mathbf{B} \\in \\mathbb{R}^{k\\times n}$, the matrix product $\\mathbf{A}\\mathbf{B}$ produces a new matrix $\\mathbf{P} \\in \\mathbb{R}^{m\\times n}$:\n",
    "$$\n",
    "    \\begin{bmatrix}\n",
    "    \\mathbf{a}^T_{row_0}\\mathbf{b}_{col_0} &\\dots& \\mathbf{a}^T_{row_0}\\mathbf{b}_{col_n} \\\\\n",
    "    \\vdots &\\ddots &\\vdots \\\\ \n",
    "    \\mathbf{a}^T_{row_m}\\mathbf{b}_{col_0} &\\dots& \\mathbf{a}^T_{row_m}\\mathbf{b}_{col_n} \n",
    "    \\end{bmatrix}\\\n",
    "$$\n",
    "\n",
    "\n",
    "Magically, in pylab there is almost no change!:\n",
    "\n",
    "```python\n",
    "# Evalutate the weighted sum - dot product\n",
    "net = dot(w,x)\n",
    "\n",
    "# Evaluate the output\n",
    "y = step(net)\n",
    "```\n",
    "where `W` is now a matrix, and `y` is a vector.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning\n",
    "Learning consists in updating the weights so that the weighted sum $y$ is more and more similar to a desired output $o_k$ when we give the input $p_k$ to the network.\n",
    "In perceptrons learning can be done online, meaning that we can update the weights each time a single input pattern is presented.\n",
    "Learning is given at each timestep by:\n",
    "$$\n",
    "\\Delta w_i = \\eta (o_k - y)x_i  \\\\\n",
    "$$\n",
    "or, in linear algebra notation:\n",
    "$$\n",
    "\\Delta \\mathbf{w} = \\eta(o_k - y)\\mathbf{x} \n",
    "$$\n",
    "where $\\eta$ is a value determining the rate of weight change per timestep (it is typically very little) and $o_k - y$ is the error in reproducing the desired value.\n",
    "In python we write:\n",
    "```python\n",
    "w += eta*(o - y)*tx\n",
    "```\n",
    "In the case of many output units the learning rule becomes:\n",
    "$$\n",
    "\\Delta w_{ij} = \\eta (o_{kj} - y_j)x_i\n",
    "$$\n",
    "which in linear algebra notation is:\n",
    "\n",
    "$$\n",
    "\\Delta \\mathbf{W} = \\eta (\\mathbf{o}_k - \\mathbf{y})\\mathbf{x}^T\n",
    "$$\n",
    "where $\\mathbf{o}_k - \\mathbf{y}$ is now a vector, $\\mathbf{x}^T$ is the vector $\\mathbf{x}$ *transposed into a row vector*, and $(\\mathbf{o}_k - \\mathbf{y})\\mathbf{x}^T$ is a new form of vector product: the [outer product](https://en.wikipedia.org/wiki/Outer_product#Vector_multiplication).\n",
    "\n",
    ">Given two vectors $\\mathbf{a} \\in \\mathbb{R}^m$ and $\\mathbf{b} \\in \\mathbb{R}^n$, the outer product $\\mathbf{a}\\mathbf{b}^T$ produces a matrix $\\mathbf{M} \\in \\mathbb{R}^{m\\times n}$:\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "    a_{0} b_{0} & \\dots & a_{0} b_{n} \\\\\n",
    "    \\vdots & \\ddots & \\vdots \\\\\n",
    "    a_{m} b_{0} & \\dots & a_{m} b_{n}\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "In python we can rewrite it as:\n",
    "```python\n",
    "W += eta*outer((o - y), tx)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">* A general rule: the **dot product** is for spreading the activity throughout a network, while the **outer product** is for weight update"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The decision boundary\n",
    "The weights of the network can be viewed as the parameters of a linear equation. This equation defines a boundary in the space of all possible inputs. All points laying above the boundary belong to the class, all the others don't belong to it.\n",
    "If the network has two inputs plus the bias the input space is a plane and the boundary is a row. In this case it is: \n",
    "\n",
    "$$x_2 = -\\frac{x_1 w_1 + w_0}{w_2}$$\n",
    "![](linear.png)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The error\n",
    "\n",
    "We can analyze if how much the network has learned by measuring the error. We compute the error at each timestep as the sum of the squared errors (SSE) for each output unit:\n",
    "$$\n",
    "E_t = \\sum_i \\frac{1}{2}(o_{it} - y_{it})^2\n",
    "$$\n",
    "Furthermore we sum all the SSE collected during each k-th presentation of all the series of the input patterns $p$:\n",
    "$$\n",
    "E_k = \\sum_{p}\\sum_{i} \\frac{1}{2}(o_{pi} - y_{pi})^2\n",
    "$$\n",
    "If the network is learning the error diminuishes and it converges to a minimum. After a while the error cannot diminuish anymore and the network reaches a steady state. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br>\n",
    "The next cell is just for styling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "marked": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "\n",
       "/* PRINT */\n",
       "\n",
       "#toc ol {\n",
       "    font-size: 20px; \n",
       "    line-height: 120%; \n",
       "    padding: 0; \n",
       "    margin-left: 20px; \n",
       "    list-style-type: decimal;\n",
       "}\n",
       "\n",
       "/* PRINT */\n",
       "div.text_cell_render table, \n",
       "div.text_cell_render  th,\n",
       "div.text_cell_render  tr,\n",
       "div.text_cell_render td {\n",
       "    border: 0px solid black;\n",
       "}\n",
       "div.MathJax_Display {padding: 40px 5px 40px 5px}\n",
       "\n",
       "div.input_area  { padding: 10px;  }\n",
       "\n",
       "div.input_area  { \n",
       "    min-width: 20em !important; \n",
       "    overflow-x: hide\n",
       "} \n",
       "div.input_area pre {  \n",
       "    min-width: 20em !important; \n",
       "}\n",
       "\n",
       "\n",
       "div.input_area  { padding: 10px; overflow: auto  }\n",
       ".rendered_html p{ text-align: left }\n",
       "div.input_area>div.highlight  { padding:10px; width: 500px !important}\n",
       "\n",
       "/* FONT_CODE */\n",
       ".input_area pre { font-size:10px; line-height:120% }\n",
       "\n",
       "/* FONT_TEXT */\n",
       "div.text_cell_render { font-size:20px;  line-height:120% }\n",
       "\n",
       "/* FONT_QUOTE */\n",
       ".text_cell_render pre { font-size:14px; line-height:120% }\n",
       "\n",
       "/* BACKGROUND */\n",
       "div .input_area { background-color:#333333;}\n",
       "blockquote { background-color:#ffff66; }\n",
       "\n",
       "/* BUILTIN */\n",
       ".input_area .highlight .bp { color: #CD5C5C } /* Name.Builtin.Pseudo */\n",
       "\n",
       "/* KEYWORD */\n",
       ".input_area .highlight .k { color: #F0E68C; font-weight: bold } /* Keyword */\n",
       ".input_area .highlight .kc { color: #F0E68C; font-weight: bold } /* Keyword.Constant */\n",
       ".input_area .highlight .kd { color: #F0E68C; font-weight: bold } /* Keyword.Declaration */\n",
       ".input_area .highlight .kn { color: #F0E68C; font-weight: bold } /* Keyword.Namespace */\n",
       ".input_area .highlight .kp { color: #F0E68C; font-weight: bold } /* Keyword.Pseudo */\n",
       ".input_area .highlight .kr { color: #F0E68C; font-weight: bold } /* Keyword.Reserved */\n",
       ".input_area .highlight .kt { color: #F0E68C; font-weight: bold } /* Keyword.Type */\n",
       ".input_area .highlight .ow { color: #F0E68C; font-weight: bold } /* Operator.Word */\n",
       "\n",
       "/* VARIABLE */\n",
       ".input_area .highlight pre { color: #FFFFFF }\n",
       ".input_area .highlight .n { color: #FFFFFF } /* Name.Variable */\n",
       ".input_area .highlight .nv { color: #FFFFFF } /* Name.Variable */\n",
       ".input_area .highlight .na { color: #FFFFFF } /* Name.Attribute */\n",
       ".input_area .highlight .no { color: #FFFFFF } /* Name.Constant */\n",
       ".input_area .highlight .nl { color: #FFFFFF } /* Name.Label */\n",
       "\n",
       "/* FUNCTION */\n",
       ".input_area .highlight .nb { color: #BDB76B } /* Name.Builtin */\n",
       ".input_area .highlight .nf { color: #BDB76B } /* Name.Function */\n",
       ".input_area .highlight .vc { color: #BDB76B } /* Name.Variable.Class */\n",
       ".input_area .highlight .vg { color: #BDB76B } /* Name.Variable.Global */\n",
       ".input_area .highlight .vi { color: #BDB76B } /* Name.Variable.Instance */\n",
       ".input_area .highlight .nc { color: #BDB76B } /* Name.Class */\n",
       ".input_area .highlight .ni { color: #BDB76B } /* Name.Entity */\n",
       ".input_area .highlight .ne { color: #BDB76B } /* Name.Exception */\n",
       ".input_area .highlight .nn { color: #BDB76B } /* Name.Namespace */\n",
       ".input_area .highlight .nt { color: #BDB76B } /* Name.Tag */\n",
       "\n",
       "\n",
       "\n",
       "/* OPERATOR */\n",
       ".input_area .highlight .o { color: #FFFFFF; font-weight:bold } /* Operator */\n",
       ".input_area .highlight .p { color: #FFFFFF; font-weight:bold } /* Operator */\n",
       "\n",
       "\n",
       "/* DECORATOR */\n",
       ".input_area .highlight .nd { color: #BDB76B } /* Name.Decorator */\n",
       "\n",
       "\n",
       "/* COMMENT */\n",
       ".input_area .highlight .c { color: #87CEEB; font-style: italic } /* Comment */\n",
       ".input_area .highlight .cm { color: #87CEEB; font-style: italic } /* Comment.Multiline */\n",
       ".input_area .highlight .cp { color: #87CEEB; } /* Comment.Preproc */\n",
       ".input_area .highlight .c1 { color: #87CEEB; font-style: italic } /* Comment.Single */\n",
       ".input_area .highlight .cs { color: #87CEEB; font-style: italic } /* Comment.Special */\n",
       "\n",
       "\n",
       "/* NUMBER */\n",
       ".input_area .highlight .mb { color: #98FB98 } /* Literal.Number.Bin */\n",
       ".input_area .highlight .mf { color: #98FB98 } /* Literal.Number.Float */\n",
       ".input_area .highlight .mh { color: #98FB98 } /* Literal.Number.Hex */\n",
       ".input_area .highlight .mi { color: #98FB98 } /* Literal.Number.Integer */\n",
       ".input_area .highlight .mo { color: #98FB98 } /* Literal.Number.Oct */\n",
       ".input_area .highlight .m { color: #98FB98 } /* Literal.Number */\n",
       ".input_area .highlight .il { color: #98FB98 } /* Literal.Number.Integer.Long */\n",
       "\n",
       "/* STRING */\n",
       ".input_area .highlight .s { color: #FFA0A0 } /* Literal.String */\n",
       ".input_area .highlight .w { color: #FFA0A0 } /* Text.Whitespace */\n",
       ".input_area .highlight .sb { color: #FFA0A0 } /* Literal.String.Backtick */\n",
       ".input_area .highlight .sc { color: #FFA0A0 } /* Literal.String.Char */\n",
       ".input_area .highlight .sd { color: #FFA0A0; font-style: italic } /* Literal.String.Doc */\n",
       ".input_area .highlight .s2 { color: #FFA0A0 } /* Literal.String.Double */\n",
       ".input_area .highlight .se { color: #FFA0A0; font-weight: bold } /* Literal.String.Escape */\n",
       ".input_area .highlight .sh { color: #FFA0A0 } /* Literal.String.Heredoc */\n",
       ".input_area .highlight .si { color: #FFA0A0; font-weight: bold } /* Literal.String.Interpol */\n",
       ".input_area .highlight .sx { color: #FFA0A0 } /* Literal.String.Other */\n",
       ".input_area .highlight .sr { color: #FFA0A0 } /* Literal.String.Regex */\n",
       ".input_area .highlight .s1 { color: #FFA0A0 } /* Literal.String.Single */\n",
       ".input_area .highlight .ss { color: #FFA0A0 } /* Literal.String.Symbol */\n",
       "\n",
       "\n",
       "\n",
       "/********************************************************************************/\n",
       "/********************************************************************************/\n",
       "\n",
       "/* JUPYTER */\n",
       "\n",
       "/* FONT_EDIT */\n",
       ".cm-s-default span { font-size:16px; line-height:120% }\n",
       "\n",
       "/* BACKGROUND_EDIT */\n",
       "div .cm-s-default { background-color: #888888;}\n",
       "\n",
       "/* CURSOR */\n",
       ".input_area .CodeMirror div.CodeMirror-cursor { border-left: 5px solid #FFFFFF; }\n",
       ".input_area .CodeMirror div.CodeMirror-secondarycursor { border-left: 5px solid #FFFFFF;}\n",
       ".input_area .CodeMirror.cm-fat-cursor div.CodeMirror-cursor { background: #FFFFFF;}\n",
       ".input_area .cm-animate-fat-cursor { background-color: #FFFFFF; }\n",
       "\n",
       "/* BUILTIN */\n",
       ".input_area .cm-s-ipython span.cm-builtin { color: #CD5C5C } \n",
       ".input_area .cm-s-ipython span.cm-variable-2 { color: #CD5C5C } \n",
       ".input_area .cm-s-ipython span.cm-variable-3 { color: #CD5C5C } \n",
       "\n",
       "/* KEYWORD */\n",
       ".input_area .cm-s-ipython span.cm-keyword { color: #F0E68C; font-weight:700 } \n",
       "\n",
       "/* VARIABLE */\n",
       ".input_area span.cm-variable { color: #FFFFFF } \n",
       ".input_area span.cm-def { color: #FFFFFF } \n",
       "\n",
       "\n",
       "/* OPERATOR */\n",
       ".input_area .cm-s-ipython span.cm-operator { color: #FFFFFF; font-weight:700 } \n",
       ".input_area .cm-s-ipython span { color: #FFFFFF; font-weight:700 } \n",
       "\n",
       "/* DECORATOR */\n",
       ".input_area .cm-s-ipython span.cm-meta { color: #BDB76B } \n",
       "\n",
       "/* COMMENT */\n",
       ".input_area .cm-s-ipython span.cm-comment { color:#87CEEB; font-style:italic } \n",
       "\n",
       "/* NUMBER */\n",
       ".input_area .cm-s-ipython span.cm-number { color: #98FB98 } \n",
       "\n",
       "/* STRING */\n",
       ".input_area .cm-s-ipython span.cm-string { color: #FFA0A0 } \n",
       ".input_area .cm-s-ipython span.cm-string-2 { color: #FFA0A0 } \n",
       "\n",
       "</style><script> \n",
       "// Converts integer to roman numeral\n",
       "function romanize(num) {\n",
       "    var lookup = {M:1000,CM:900,D:500,CD:400,C:100,XC:90,L:50,XL:40,X:10,IX:9,V:5,IV:4,I:1},\n",
       "    roman = '',\n",
       "    i;\n",
       "    for ( i in lookup ) {\n",
       "        while ( num >= lookup[i] ) {\n",
       "            roman += i;\n",
       "            num -= lookup[i];\n",
       "        }\n",
       "    }\n",
       "    return roman;\n",
       "}\n",
       "\n",
       "// Builds a <ul> Table of Contents from all <headers> in DOM\n",
       "function createTOC(){\n",
       "    var toc = \"\";\n",
       "    var level = 0;\n",
       "    var levels = {}\n",
       "    $('#toc').html('');\n",
       "\n",
       "    $(\":header\").each(function(i){\n",
       "        if (this.id=='tocheading'){return;}\n",
       "\n",
       "        titleText = this.innerHTML;\n",
       "        openLevel = this.tagName[1];\n",
       "        if(openLevel>1) {\n",
       "            openLevel-=1\n",
       "\n",
       "        if (levels[openLevel]){\n",
       "            levels[openLevel] += 1;\n",
       "        } else{\n",
       "            levels[openLevel] = 1;\n",
       "        }\n",
       "\n",
       "        if (openLevel > level) {\n",
       "            toc += (new Array(openLevel - level + 1)).join('<ol type=\"1\" class=\"toc\">');\n",
       "        } else if (openLevel < level) {\n",
       "            toc += (new Array(level - openLevel + 1)).join(\"</ol>\");\n",
       "            for (i=level;i>openLevel;i--){levels[i]=0;}\n",
       "        }\n",
       "\n",
       "        level = parseInt(openLevel);\n",
       "\n",
       "\n",
       "        if (this.id==''){this.id = this.innerHTML.replace(/ /g,\"-\")}\n",
       "        var anchor = this.id;\n",
       "\n",
       "        toc += '<li><a href=\"#' + anchor + '\">' + titleText\n",
       "        + '</a></li>';\n",
       "    }\n",
       "\n",
       "    });\n",
       "\n",
       "\n",
       "    if (level) {\n",
       "        toc += (new Array(level + 1)).join(\"</ol>\");\n",
       "    }\n",
       "\n",
       "\n",
       "    $('#toc').append(toc);\n",
       "\n",
       "};\n",
       "\n",
       "// Executes the createToc function\n",
       "setTimeout(function(){createTOC();},100);\n",
       "\n",
       "// Rebuild to TOC every minute\n",
       "setInterval(function(){createTOC();},60000);\n",
       "</script>\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.core.display import HTML\n",
    "def css_styling():\n",
    "    styles = open(\"../style/ipybn.css\", \"r\").read()\n",
    "    return HTML(styles)\n",
    "css_styling()"
   ]
  }
 ],
 "metadata": {
  "css": [
   ""
  ],
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
